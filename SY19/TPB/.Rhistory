data_df[not (data_df$V1 %in% c("A", "B"))]
data_df[%not% (data_df$V1 %in% c("A", "B")),]
data_df[not (data_df$V1 %in% c("A", "B")),]
data_df[not data_df$V1 %in% c("A", "B"),]
data_df[!data_df$V1 %in% c("A", "B"),]
# %in%
# trier par lettre, reconnaître de A à J
names.aj = c("A", "B", "C", "D", "E", "F", "G", "H", "I", "J")
subset.aj = data_df[data_df$V1 %in% names.aj,]
subset.aj.other = data_df[!data_df$V1 %in% names.aj,]
data_df[!data_df$V1 %in% c("A", "B"),]
aj.other
subset.aj.other
length(subset.aj)
length(subset.aj[0])
length(subset.aj[1])
length(subset.aj[1,])
length(subset.aj[,1])
WORKING = subset.aj
n = length(WORKING[,1])
train.index = sample(n, size = floor(n * 0.8), replace = FALSE)
WORKING[, train.index]
WORKING[train.index,]
WORKING[train.index,2:]
WORKING[train.index,1:]
WORKING[train.index,][2:]
WORKING[train.index,][,2:]
WORKING[train.index,][,2:length(WORKING)]
WORKING[train.index,2:length(WORKING)]
WORKING[train.index,-V1]
WORKING[train.index,1]
library(kernlab)
WORKING = subset.aj
n = length(WORKING[,1])
train.index = sample(n, size = floor(n * 0.8), replace = FALSE)
X.train = WORKING[train.index, 2:length(WORKING)]
Y.train = WORKING[train.index, 1]
X.test = WORKING[-train.index, 2:length(WORKING)]
Y.test = WORKING[-train.index, 1]
ksvm(X.train, Y.train)
length(X.train)
length(Y.train)
Y.train[0]
Y.train[1]
X.train[1]
X.train
WORKING
length(Y.train)
length(X.train[1])
length(X.train[2])
length(X.train[,1])
as.dataframe(read.table("letter-recognition.data", header = FALSE))
as.data.frame(read.table("letter-recognition.data", header = FALSE))
data_df <- as.data.frame(read.table("letter-recognition.data", header = FALSE))
# %in%
# trier par lettre, reconnaître de A à J
names.aj = c("A", "B", "C", "D", "E", "F", "G", "H", "I", "J")
subset.aj = data_df[data_df$V1 %in% names.aj,]
subset.aj.other = data_df[!data_df$V1 %in% names.aj,]
library(kernlab)
WORKING = subset.aj
n = length(WORKING[,1])
train.index = sample(n, size = floor(n * 0.8), replace = FALSE)
X.train = WORKING[train.index, 2:length(WORKING)]
Y.train = WORKING[train.index, 1]
X.test = WORKING[-train.index, 2:length(WORKING)]
Y.test = WORKING[-train.index, 1]
ksvm(X.train, Y.train)
WORKING
Y = WORKING[, 1]
Y
Y.train
Y
WORKING[, 2:length(WORKING)]
length(WORKING[, 2:length(WORKING)])
library(kernlab)
WORKING = subset.aj
n = nrow(WORKING)
train.index = sample(n, size = floor(n * 0.8), replace = FALSE)
X.train = WORKING[train.index, 2:ncol(WORKING)]
Y.train = as.factor(WORKING[train.index, 1])
X.test = WORKING[-train.index, 2:ncol(WORKING)]
Y.test = as.factor(WORKING[-train.index, 1])
ksvm(X.train, Y.train)
X.test
Y.test
library(kernlab)
WORKING = subset.aj
WORKING$V1 = as.factor(WORKING$V1)
n = nrow(WORKING)
train.index = sample(n, size = floor(n * 0.8), replace = FALSE)
X.train = WORKING[train.index, ]
X.test = WORKING[-train.index, ]
ksvm(V1 ~ ., data = X.train, kernel = "rfbdot", C = 1)
library(kernlab)
WORKING = subset.aj
WORKING$V1 = as.factor(WORKING$V1)
n = nrow(WORKING)
train.index = sample(n, size = floor(n * 0.8), replace = FALSE)
X.train = WORKING[train.index, ]
X.test = WORKING[-train.index, ]
ksvm(V1 ~ ., data = X.train, kernel = "rbfdot", C = 1)
library(kernlab)
WORKING = subset.aj
WORKING$V1 = as.factor(WORKING$V1)
n = nrow(WORKING)
train.index = sample(n, size = floor(n * 0.8), replace = FALSE)
X.train = WORKING[train.index, ]
X.test = WORKING[-train.index, ]
ksvm(V1 ~ ., data = X.train, kernel = "rbfdot", C = 1)
pred = predict(clf, newdata = X.test)
pred = predict(clf, newdata = X.test)
library(kernlab)
WORKING = subset.aj
WORKING$V1 = as.factor(WORKING$V1)
n = nrow(WORKING)
train.index = sample(n, size = floor(n * 0.8), replace = FALSE)
X.train = WORKING[train.index, ]
X.test = WORKING[-train.index, ]
clf = ksvm(V1 ~ ., data = X.train, kernel = "rbfdot", C = 1)
pred = predict(clf, newdata = X.test)
cat("\n", mean(pred != X.test$V1), "\n")
# un truc interessant peut etre de regarde ou il fait ses erreurs :
table(pred, X.test$V1)
library(kernlab)
WORKING = subset.aj
WORKING$V1 = as.factor(WORKING$V1)
n = nrow(WORKING)
train.index = sample(n, size = floor(n * 0.8), replace = FALSE)
X.train = WORKING[train.index, ]
X.test = WORKING[-train.index, ]
clf = ksvm(V1 ~ ., data = X.train, kernel = "rbfdot", C = 1)
pred = predict(clf, newdata = X.test)
cat("\n", mean(pred != X.test$V1), "\n")
# un truc interessant peut etre de regarde ou il fait ses erreurs :
table(pred, X.test$V1)
data_df <- as.data.frame(read.table("letter-recognition.data", header = FALSE))
data_df$V1 = as.factor(data_df$V1)
# %in%
# trier par lettre, reconnaître de A à J
names.aj = c("A", "B", "C", "D", "E", "F", "G", "H", "I", "J")
subset.aj = data_df[data_df$V1 %in% names.aj,]
subset.aj.other = data_df[!data_df$V1 %in% names.aj,]
library(kernlab)
WORKING = subset.aj
n = nrow(WORKING)
train.index = sample(n, size = floor(n * 0.8), replace = FALSE)
X.train = WORKING[train.index, ]
X.test = WORKING[-train.index, ]
clf = ksvm(V1 ~ ., data = X.train, kernel = "rbfdot", C = 1)
pred = predict(clf, newdata = X.test)
cat("\n", mean(pred != X.test$V1), "\n")
# un truc interessant peut etre de regarde ou il fait ses erreurs :
table(pred, X.test$V1)
library(kernlab)
WORKING = subset.aj
n = nrow(WORKING)
train.index = sample(n, size = floor(n * 0.8), replace = FALSE)
X.train = WORKING[train.index, ]
X.test = WORKING[-train.index, ]
clf = ksvm(V1 ~ ., data = X.train, kernel = "rbfdot", C = 1)
pred = predict(clf, newdata = X.test)
cat("\n", mean(pred != X.test$V1), "\n")
# un truc interessant peut etre de regarde ou il fait ses erreurs :
table(pred, X.test$V1)[, 1:10]
library(kernlab)
WORKING = subset.aj
n = nrow(WORKING)
train.index = sample(n, size = floor(n * 0.8), replace = FALSE)
X.train = WORKING[train.index, ]
X.test = WORKING[-train.index, ]
clf = ksvm(V1 ~ ., data = X.train, kernel = "rbfdot", C = 1)
pred = predict(clf, newdata = X.test)
cat("\n", mean(pred != X.test$V1), "\n")
# un truc interessant peut etre de regarde ou il fait ses erreurs :
table(pred, X.test$V1)[1:10, 1:10]
library(kernlab)
WORKING = subset.aj
n = nrow(WORKING)
train.index = sample(n, size = floor(n * 0.8), replace = FALSE)
X.train = WORKING[train.index, ]
X.test = WORKING[-train.index, ]
clf = ksvm(V1 ~ ., data = X.train, kernel = "rbfdot", C = 1)
pred = predict(clf, newdata = X.test)
cat("\n", mean(pred != X.test$V1), "\n")
# un truc interessant peut etre de regarde ou il fait ses erreurs :
table(pred, X.test$V1)[1:12, 1:12]
pred = predict(clf, newdata = subset.aj.other)
cat("\n", mean(pred != subset.aj.other$V1), "\n")
# un truc interessant peut etre de regarde ou il fait ses erreurs :
table(pred, subset.aj.other$V1)[8:25, 8:25]
as.factor(ifelse("1", "0", X.train$V1 == "A"))
ifelse("1", "0", X.train$V1 == "A")
ifelse("1", "0", X.train$V1 == "A")
?ifelse
ifelse(X.train$V1 == "A", "1", "0")
as.factor(ifelse(X.train$V1 == "A", "1", "0"))
X.train2$V1 = as.factor(ifelse(X.train$V1 == "A", "1", "0"))
X.train2 = X.train
X.test2 = X.test
X.train2$V1 = as.factor(ifelse(X.train$V1 == "A", "1", "0"))
X.test2$V1 = as.factor(ifelse(X.test$V1 == "A", "1", "0"))
clf = ksvm(V1 ~ ., data = X.train2, kernel = "rbfdot", C = 1)
pred = predict(clf, newdata = subset.aj.other)
table(pred, subset.aj.other$V1)[8:25, 8:25]
X.train2 = X.train
X.test2 = X.test
X.train2$V1 = as.factor(ifelse(X.train$V1 == "A", "1", "0"))
X.test2$V1 = as.factor(ifelse(X.test$V1 == "A", "1", "0"))
clf = ksvm(V1 ~ ., data = X.train2, kernel = "rbfdot", C = 1)
pred = predict(clf, newdata = subset.aj.other)
table(pred, subset.aj.other$V1)
X.train2 = X.train
X.test2 = X.test
X.train2$V1 = as.factor(ifelse(X.train$V1 == "A", "1", "0"))
X.test2$V1 = as.factor(ifelse(X.test$V1 == "A", "1", "0"))
clf = ksvm(V1 ~ ., data = X.train2, kernel = "rbfdot", C = 1)
pred = predict(clf, newdata = subset.aj.other)
table(pred, subset.aj.other$V1)[8:20]
X.train2 = X.train
X.test2 = X.test
X.train2$V1 = as.factor(ifelse(X.train$V1 == "A", "1", "0"))
X.test2$V1 = as.factor(ifelse(X.test$V1 == "A", "1", "0"))
clf = ksvm(V1 ~ ., data = X.train2, kernel = "rbfdot", C = 1)
pred = predict(clf, newdata = subset.aj.other)
table(pred, subset.aj.other$V1)[2, 8:20]
X.train2 = X.train
X.test2 = X.test
X.train2$V1 = as.factor(ifelse(X.train$V1 == "A", "1", "0"))
X.test2$V1 = as.factor(ifelse(X.test$V1 == "A", "1", "0"))
clf = ksvm(V1 ~ ., data = X.train2, kernel = "rbfdot", C = 1)
pred = predict(clf, newdata = subset.aj.other)
table(pred, subset.aj.other$V1)[1:2, 8:20]
X.train2 = X.train
X.test2 = X.test
X.train2$V1 = as.factor(ifelse(X.train$V1 == "A", "1", "0"))
X.test2$V1 = as.factor(ifelse(X.test$V1 == "A", "1", "0"))
clf = ksvm(V1 ~ ., data = X.train2, kernel = "rbfdot", C = 1)
pred = predict(clf, newdata = subset.aj.other)
table(pred, subset.aj.other$V1)[, 8:20]
X.train2 = X.train
X.test2 = X.test
X.train2$V1 = as.factor(ifelse(X.train$V1 == "A", "1", "0"))
X.test2$V1 = as.factor(ifelse(X.test$V1 == "A", "1", "0"))
clf = ksvm(V1 ~ ., data = X.train2, kernel = "rbfdot", C = 1)
pred = predict(clf, newdata = subset.aj.other)
table(pred, subset.aj.other$V1)[, 10:ncol(pred)]
X.train2 = X.train
X.test2 = X.test
X.train2$V1 = as.factor(ifelse(X.train$V1 == "A", "1", "0"))
X.test2$V1 = as.factor(ifelse(X.test$V1 == "A", "1", "0"))
clf = ksvm(V1 ~ ., data = X.train2, kernel = "rbfdot", C = 1)
pred = predict(clf, newdata = subset.aj.other)
table(pred, subset.aj.other$V1)[, 10:nrow(pred)]
X.train2 = X.train
X.test2 = X.test
X.train2$V1 = as.factor(ifelse(X.train$V1 == "A", "1", "0"))
X.test2$V1 = as.factor(ifelse(X.test$V1 == "A", "1", "0"))
clf = ksvm(V1 ~ ., data = X.train2, kernel = "rbfdot", C = 1)
pred = predict(clf, newdata = subset.aj.other)
table(pred, subset.aj.other$V1)[, 10:26]
pred = predict(clf, newdata = subset.aj.other)
cat("\n", mean(pred != subset.aj.other$V1), "\n")
pred = predict(clf, newdata = subset.aj.other)
cat("\n", mean(pred != subset.aj.other$V1), "\n")
data_df <- as.data.frame(read.table("letter-recognition.data", header = FALSE))
data_df$V1 = as.factor(data_df$V1)
# %in%
# trier par lettre, reconnaître de A à J
names.aj = c("A", "B", "C", "D", "E", "F", "G", "H", "I", "J")
subset.aj = data_df[data_df$V1 %in% names.aj,]
subset.aj.other = data_df[!data_df$V1 %in% names.aj,]
library(kernlab)
WORKING = subset.aj
n = nrow(WORKING)
train.index = sample(n, size = floor(n * 0.8), replace = FALSE)
X.train = WORKING[train.index, ]
X.test = WORKING[-train.index, ]
clf = ksvm(V1 ~ ., data = X.train, kernel = "rbfdot", C = 1)
pred = predict(clf, newdata = X.test)
cat("\n", mean(pred != X.test$V1), "\n")
# un truc interessant peut etre de regarde ou il fait ses erreurs :
table(pred, X.test$V1)[1:12, 1:12]
pred = predict(clf, newdata = subset.aj.other)
cat("\n", mean(pred != subset.aj.other$V1), "\n")
# un truc interessant peut etre de regarde ou il fait ses erreurs :
table(pred, subset.aj.other$V1)[8:25, 8:25]
pred = predict(clf, newdata = subset.aj.other)
cat("\n", mean(pred != subset.aj.other$V1), "\n")
# un truc interessant peut etre de regarde ou il fait ses erreurs :
table(pred, subset.aj.other$V1)[1:15, 8:25]
pred = predict(clf, newdata = subset.aj.other)
cat("\n", mean(pred != subset.aj.other$V1), "\n")
# un truc interessant peut etre de regarde ou il fait ses erreurs :
table(pred, subset.aj.other$V1)[1:15, 9:26]
pred = predict(clf, newdata = subset.aj.other)
cat("\n", mean(pred != subset.aj.other$V1), "\n")
# un truc interessant peut etre de regarde ou il fait ses erreurs :
table(pred, subset.aj.other$V1)[1:26, 10:26]
X.train2 = X.train
X.test2 = X.test
X.train2$V1 = as.factor(ifelse(X.train$V1 == "A", "1", "0"))
X.test2$V1 = as.factor(ifelse(X.test$V1 == "A", "1", "0"))
clf = ksvm(V1 ~ ., data = X.train2, kernel = "rbfdot", C = 1)
pred = predict(clf, newdata = subset.aj.other)
table(pred, subset.aj.other$V1)[, 10:26]
occ = ksvm(as.matrix(X.train[, -1]), type = "one-svc", kernel = "rbfdot")
pred = predict(occ, newdata = rbind(X.test, letter2)[, -1])
occ = ksvm(as.matrix(X.train[, -1]), type = "one-svc", kernel = "rbfdot")
pred = predict(occ, newdata = rbind(X.test, subset.aj.other)[, -1])
pred = ifelse(pred, "in", "out") # en ou hors de la distribution
y = factor(c(rep("in", norw(X.test)), rep("out", nrow(subset.aj.other))))
occ = ksvm(as.matrix(X.train[, -1]), type = "one-svc", kernel = "rbfdot")
pred = predict(occ, newdata = rbind(X.test, subset.aj.other)[, -1])
pred = ifelse(pred, "in", "out") # en ou hors de la distribution
y = factor(c(rep("in", nrow(X.test)), rep("out", nrow(subset.aj.other))))
occ = ksvm(as.matrix(X.train[, -1]), type = "one-svc", kernel = "rbfdot")
pred = predict(occ, newdata = rbind(X.test, subset.aj.other)[, -1])
pred = ifelse(pred, "in", "out") # en ou hors de la distribution
y = factor(c(rep("in", nrow(X.test)), rep("out", nrow(subset.aj.other))))
table(pred, y)
y.class = c(X.test$V1, subset.aj.other$V1)
table(y.class, pred)
occ = ksvm(as.matrix(X.train[, -1]), type = "one-svc", kernel = "rbfdot")
pred = predict(occ, newdata = rbind(X.test, subset.aj.other)[, -1])
pred = ifelse(pred, "in", "out") # en ou hors de la distribution
y = factor(c(rep("in", nrow(X.test)), rep("out", nrow(subset.aj.other))))
table(pred, y)
y.class = c(X.test$V1, subset.aj.other$V1)
# en fait on va en faire un barplot parce que c'est pas très lisible comme ça
a = table(y.class, pred)
b = a[, 2] / (a[, 1] + a[, 2])
barplot(b)
letter = "A" # représentant de la classe unique
X.train2 = X.train
X.test2 = X.test
X.train2$V1 = as.factor(ifelse(X.train$V1 == letter, "1", "0"))
X.test2$V1 = as.factor(ifelse(X.test$V1 == letter, "1", "0"))
clf = ksvm(V1 ~ ., data = X.train2, kernel = "rbfdot", C = 1)
pred = predict(clf, newdata = subset.aj.other)
table(pred, subset.aj.other$V1)[, 10:26]
occ = ksvm(as.matrix(X.train[, -1]), type = "one-svc", kernel = "rbfdot")
# on cherche les taux de rejet
pred = predict(occ, newdata = rbind(X.test, subset.aj.other)[, -1])
pred = ifelse(pred, "in", "out") # en ou hors de la distribution
y = factor(c(rep("in", nrow(X.test)), rep("out", nrow(subset.aj.other))))
table(pred, y)
y.class = c(X.test$V1, subset.aj.other$V1)
# en fait on va en faire un barplot parce que c'est pas très lisible comme ça
a = table(y.class, pred)
b = a[, 2] / (a[, 1] + a[, 2])
barplot(b)
actual_labels = y.class
predicted_scores = predict(occ, rbind(X.test, subset.aj.other)[, -1], type = "decision")
plot(roc(actual_labels, predicted_scores))
library(pROC)
actual_labels = y.class
predicted_scores = predict(occ, rbind(X.test, subset.aj.other)[, -1], type = "decision")
plot(roc(actual_labels, predicted_scores))
library(pROC)
actual_labels = y.class
predicted_scores = predict(occ, rbind(X.test, subset.aj.other)[, -1], type = "decision")[, 1]
plot(roc(actual_labels, predicted_scores))
data = as.data.frame(read.table("flame.txt", header = FALSE))
View(data)
View(data)
data[, V3 == "1"]
data[, data$V3 == 1]
data[data$V3 == 1, ]
data = as.data.frame(read.table("flame.txt", header = FALSE))
F1 = data[data$V3 == 1, ]
F2 = data[data$V3 == 2, ]
F1[1, ]
F1[, 1]
data = as.data.frame(read.table("flame.txt", header = FALSE))
F1 = data[data$V3 == 1, ]
F2 = data[data$V3 == 2, ]
plot(F1[, 1], F1[, 2])
data = as.data.frame(read.table("flame.txt", header = FALSE))
F1 = data[data$V3 == 1, ]
F2 = data[data$V3 == 2, ]
plot(F1[, 1], F1[, 2])
plot(F2[, 1], F2[, 2])
data = as.data.frame(read.table("flame.txt", header = FALSE))
F1 = data[data$V3 == 1, 1:2]
F2 = data[data$V3 == 2, 1:2]
plot(F1[, 1], F1[, 2])
plot(F2[, 1], F2[, 2])
F2
data = as.data.frame(read.table("flame.txt", header = FALSE))
F1 = data[data$V3 == 1, 1:2]
F2 = data[data$V3 == 2, 1:2]
plot(F1[, 1], F1[, 2])
plot(F2[, 1], F2[, 2])
plot(data[,1,], data[,2,])
data = as.data.frame(read.table("flame.txt", header = FALSE))
F1 = data[data$V3 == 1, 1:2]
F2 = data[data$V3 == 2, 1:2]
plot(F1[, 1], F1[, 2])
plot(F2[, 1], F2[, 2])
plot(data[,1], data[,2], col=data[,3])
kmeans(data[, 1:2], 2)
?plot
km = kmeans(data[, 1:2], 2)
plot(data[,1], data[,2], col=km$cluster)
data = as.data.frame(read.table("flame.txt", header = FALSE))
data = scale(data)
F1 = data[data$V3 == 1, 1:2]
data[, 1] = scale(data[, 1])
data
data = as.data.frame(read.table("flame.txt", header = FALSE))
F1 = data[data$V3 == 1, 1:2]
F2 = data[data$V3 == 2, 1:2]
plot(F1[, 1], F1[, 2])
plot(F2[, 1], F2[, 2])
plot(data[,1], data[,2], col=data[,3])
data[, 1] = scale(data[, 1])
data[, 2] = scale(data[, 2])
data = as.data.frame(read.table("flame.txt", header = FALSE))
F1 = data[data$V3 == 1, 1:2]
F2 = data[data$V3 == 2, 1:2]
plot(F1[, 1], F1[, 2])
plot(F2[, 1], F2[, 2])
plot(data[,1], data[,2], col=data[,3])
data$V1 = scale(data$V1)
data$V2 = scale(data$V2)
km = kmeans(data[, 1:2], 2)
plot(data[,1], data[,2], col=km$cluster)
km = kmeans(data[, 1:2], 2)
plot(data[,1], data[,2], col=km$cluster)
km = kmeans(data[, 1:2], 2)
plot(data[,1], data[,2], col=km$cluster)
library(mclust)
Mclust(data[, 1:2])
library(mclust)
res = Mclust(data[, 1:2])
plot(res, what = "classification")
library(mclust)
res = Mclust(data[, 1:2]) # G = 3
plot(res, what = "classification")
plot(X, col=res$classification)
library(mclust)
res = Mclust(data[, 1:2]) # G = 3
plot(res, what = "classification")
plot(X[, 1], X[, 2], col=res$classification)
data_df <- as.data.frame(read.table("letter-recognition.data", header = FALSE))
data_df$V1 = as.factor(data_df$V1)
# %in%
# trier par lettre, reconnaître de A à J
names.aj = c("A", "B", "C", "D", "E", "F", "G", "H", "I", "J")
subset.aj = data_df[data_df$V1 %in% names.aj,]
subset.aj.other = data_df[!data_df$V1 %in% names.aj,]
library(kernlab)
WORKING = subset.aj
n = nrow(WORKING)
train.index = sample(n, size = floor(n * 0.8), replace = FALSE)
X.train = WORKING[train.index, ]
X.test = WORKING[-train.index, ]
clf = ksvm(V1 ~ ., data = X.train, kernel = "rbfdot", C = 1)
pred = predict(clf, newdata = X.test)
cat("\n", mean(pred != X.test$V1), "\n")
# un truc interessant peut etre de regarde ou il fait ses erreurs :
table(pred, X.test$V1)[1:12, 1:12]
pred = predict(clf, newdata = subset.aj.other)
cat("\n", mean(pred != subset.aj.other$V1), "\n")
# un truc interessant peut etre de regarde ou il fait ses erreurs :
table(pred, subset.aj.other$V1)[1:26, 10:26]
letter = "A" # représentant de la classe unique
X.train2 = X.train
X.test2 = X.test
X.train2$V1 = as.factor(ifelse(X.train$V1 == letter, "1", "0"))
X.test2$V1 = as.factor(ifelse(X.test$V1 == letter, "1", "0"))
clf = ksvm(V1 ~ ., data = X.train2, kernel = "rbfdot", C = 1)
pred = predict(clf, newdata = subset.aj.other)
table(pred, subset.aj.other$V1)[, 10:26]
occ = ksvm(as.matrix(X.train[, -1]), type = "one-svc", kernel = "rbfdot")
# on cherche les taux de rejet
pred = predict(occ, newdata = rbind(X.test, subset.aj.other)[, -1])
pred = ifelse(pred, "in", "out") # en ou hors de la distribution
y = factor(c(rep("in", nrow(X.test)), rep("out", nrow(subset.aj.other))))
table(pred, y)
y.class = c(X.test$V1, subset.aj.other$V1)
# en fait on va en faire un barplot parce que c'est pas très lisible comme ça
a = table(y.class, pred)
b = a[, 2] / (a[, 1] + a[, 2])
barplot(b)
library(pROC)
actual_labels = y.class
predicted_scores = predict(occ, rbind(X.test, subset.aj.other)[, -1], type = "decision")[, 1]
plot(roc(actual_labels, predicted_scores))
data = as.data.frame(read.table("flame.txt", header = FALSE))
F1 = data[data$V3 == 1, 1:2]
F2 = data[data$V3 == 2, 1:2]
plot(F1[, 1], F1[, 2])
plot(F2[, 1], F2[, 2])
plot(data[,1], data[,2], col=data[,3])
data$V1 = scale(data$V1)
data$V2 = scale(data$V2)
X = data[, 1:2]
km = kmeans(data[, 1:2], 2)
plot(data[,1], data[,2], col=km$cluster)
library(mclust)
res = Mclust(data[, 1:2]) # G = 3
plot(res, what = "classification")
plot(X, col=res$classification)
library(mclust)
res = Mclust(data[, 1:2]) # G = 3
plot(res, what = "classification")
plot(X, col=ifelse(res$classification == 1, 1, 2))
kkm = kkmeans(X, centers = 2, kernel = "rbfdot")
library(kernlab)
kkm = kkmeans(X, centers = 2, kernel = "rbfdot")
